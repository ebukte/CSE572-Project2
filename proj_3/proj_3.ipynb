{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file and save data into separate lists\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when read the data from CSV, the time stamp and associated GMC value should be reversed\n",
    "def read_raw_data():\n",
    "    x_1 =[]\n",
    "    x_2 =[]\n",
    "\n",
    "    for i in range (5):\n",
    "        x_1=[]\n",
    "        x_2=[]\n",
    "        with open(r'.\\mealData'+str(i+1)+'.csv','rt')as f:\n",
    "            data = csv.reader(f)\n",
    "            rows_x=[row for idx, row in enumerate(data) if idx<50]# only use first 20 rows of the data\n",
    "            for row in rows_x:\n",
    "                x_1.append(row)\n",
    "        with open(r'.\\MealAmountData'+str(i+1)+'.csv','rt')as ff:\n",
    "            data = csv.reader(ff)\n",
    "            rows_x=[row for idx, row in enumerate(data) if idx<50]# only use first 20 rows of the data\n",
    "            for row in rows_x:\n",
    "                x_2.append(row)\n",
    "        if i==0:\n",
    "            x1 = x_1\n",
    "            x2 = x_2\n",
    "        elif i!=0:\n",
    "            x1 = x1+x_1\n",
    "            x2 = x2+x_2\n",
    "    return x1,x2\n",
    "\n",
    "# this func is used to remove the data which contains 'NaN' and only use the first 30 data\n",
    "def smooth_data(y,x):\n",
    "    idx = []\n",
    "    size_y = len(y)\n",
    "    for i in range (size_y):\n",
    "        y[i] = y[i][:30]\n",
    "        y[i] = y[i][::-1]\n",
    "        if (len(y[i])!= 30):\n",
    "            idx.append(i)\n",
    "        elif 'NaN' in y[i]:\n",
    "            idx.append(i)      \n",
    "    for j in range (len(idx),0,-1):\n",
    "        del y[idx[j-1]]\n",
    "        del x[idx[j-1]]\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from meal data: 250\n",
      "Number of meal amount data: 250\n",
      "Number of rows from the processed meal data:  211\n",
      "Number of rows from the processed meal amount data:  211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1,x2 = read_raw_data()\n",
    "print('Number of rows from meal data:',len(x1))\n",
    "print('Number of meal amount data:',len(x2))\n",
    "\n",
    "x1, x2 = smooth_data(x1, x2)\n",
    "print(\"Number of rows from the processed meal data: \",len(x1) )\n",
    "print(\"Number of rows from the processed meal amount data: \",len(x2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth(x2):\n",
    "    bin_truth = []\n",
    "    for i in range (len(x2)):\n",
    "        if int(x2[i][0]) == 0:\n",
    "            bin_truth.append(1)\n",
    "        elif (int(x2[i][0])>0) and (int(x2[i][0])<=20):\n",
    "            bin_truth.append(2)\n",
    "        elif (int(x2[i][0])>20) and (int(x2[i][0])<=40):\n",
    "            bin_truth.append(3)\n",
    "        elif (int(x2[i][0])>40) and (int(x2[i][0])<=60):\n",
    "            bin_truth.append(4)\n",
    "        elif (int(x2[i][0])>60) and (int(x2[i][0])<=80):\n",
    "            bin_truth.append(5)\n",
    "        elif (int(x2[i][0])>80) and (int(x2[i][0])<=100):\n",
    "            bin_truth.append(6)\n",
    "    return bin_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_truth = extract_ground_truth(x2)\n",
    "bin_truth = np.asarray(bin_truth)\n",
    "# print(\"number of points in Bin 1\",bin_truth.count(1))\n",
    "# print(\"number of points in Bin 2\",bin_truth.count(2))\n",
    "# print(\"number of points in Bin 3\",bin_truth.count(3))\n",
    "# print(\"number of points in Bin 4\",bin_truth.count(4))\n",
    "# print(\"number of points in Bin 5\",bin_truth.count(5))\n",
    "# print(\"number of points in Bin 6\",bin_truth.count(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the avg of changing velocity with window size 3, result in 10 features\n",
    "def avg_vel(y):\n",
    "    average = sum(y)/len(y)\n",
    "    vel_y = []\n",
    "    avg_vel = []\n",
    "    window_size = 3\n",
    "    for i in range (len(y)-1):\n",
    "        vel = y[i+1]-y[i]\n",
    "        vel_y.append(vel)\n",
    "    np.asarray(vel_y)\n",
    "\n",
    "    for i in range (int(len(y)/window_size)):\n",
    "        if i != (int((len(y)/window_size)-1)):\n",
    "            avg = np.average(vel_y[(i*3):(i*3)+3])\n",
    "        avg_vel.append(avg)\n",
    "    array_vel = np.asarray(avg_vel)\n",
    "    array_vel = normalize(array_vel[:,np.newaxis], axis=0).ravel()\n",
    "#     array_vel = (array_vel - min(array_vel))/(max(array_vel)-min(array_vel))\n",
    "    return array_vel\n",
    "\n",
    "# function for calculating the avg of meal amount with window size 3, result in 10 features\n",
    "def avg_win(y):\n",
    "    avg_win = []\n",
    "    window_size = 3\n",
    "    for i in range (int(len(y)/window_size)):\n",
    "        if i != (int((len(y)/window_size)-1)):\n",
    "            avg = np.average(y[(i*3):(i*3)+3])\n",
    "        avg_win.append(avg)\n",
    "    array_win = np.asarray(avg_win)\n",
    "    array_win = normalize(array_win[:,np.newaxis], axis=0).ravel()\n",
    "#     array_vel = (array_vel - min(array_vel))/(max(array_vel)-min(array_vel))\n",
    "    return array_win\n",
    "\n",
    "def max_increase(y):\n",
    "    change = []\n",
    "    y = list(map(int, y))\n",
    "    y_0 = y[5]\n",
    "    y_max = max(y[5:])\n",
    "    y_end = y[29]\n",
    "    max_increase = (y_max - y_0)/y_0\n",
    "    max_decrease = (y_max - y_end)/y_end\n",
    "    before_change = max(y[:5])-min(y[:5])\n",
    "    change.append(max_increase)\n",
    "    change.append(max_decrease)\n",
    "    change.append(before_change)\n",
    "    change = np.asarray(change,dtype=np.float32)\n",
    "    changed = normalize(change[:,np.newaxis], axis=0).ravel()\n",
    "#     changed = (change-min(change))/(max(change)-min(change))\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature and save it into feature metricx\n",
    "for i in range(len(x1)):\n",
    "    yy = np.asarray(x1[i],dtype=np.float32)\n",
    "    f1 = avg_vel(yy)\n",
    "    f2 = max_increase(yy)\n",
    "    f1 = np.concatenate((f1, f2), axis=None)\n",
    "#     f3 = avg_win(yy)\n",
    "#     f1 = np.concatenate((f12, f3), axis=None)\n",
    "    if i == 0:\n",
    "        feature_m1 = f1\n",
    "    else:\n",
    "        feature_m1 = np.vstack((feature_m1,f1))\n",
    "with open('feature_m1.pkl','wb') as f:\n",
    "    pickle.dump(feature_m1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model_kmeans(label,feature_m1,n_cluster,idx_keep,bin_truth):\n",
    "    cluster = []\n",
    "    bin_cluster = []\n",
    "    bin_index = []\n",
    "    result = []\n",
    "    bin_1 = []\n",
    "    bin_2 = []\n",
    "    bin_3 = []\n",
    "    bin_4 = []\n",
    "    bin_5 = []\n",
    "    bin_6 = []\n",
    "    bin_1_idx = []\n",
    "    bin_2_idx = []\n",
    "    bin_3_idx = []\n",
    "    bin_4_idx = []\n",
    "    bin_5_idx = []\n",
    "    bin_6_idx = []\n",
    "    idx_save = []\n",
    "    for j in range (n_cluster):\n",
    "        cluster_j = [ i for i in range(len(label)) if label[i] == j ]\n",
    "        idx_save_j = [idx_keep[i] for i in cluster_j]\n",
    "                \n",
    "        cluster.append(cluster_j)\n",
    "        idx_save.append(idx_save_j)\n",
    "    for j in range (n_cluster):\n",
    "        result_label = [bin_truth[i] for i in cluster[j]]\n",
    "#         print(max(set(result_label), key=result_label.count), \" \", len(result_label))\n",
    "        result.append(max(set(result_label), key=result_label.count))\n",
    "    for k in range (n_cluster):\n",
    "        if result[k]==1:\n",
    "            bin_1 = bin_1 + cluster[k]\n",
    "            bin_1_idx = bin_1_idx + idx_save[k]\n",
    "        elif result[k]==2:\n",
    "            bin_2 = bin_2 + cluster[k]\n",
    "            bin_2_idx = bin_2_idx + idx_save[k]\n",
    "        elif result[k]==3:\n",
    "            bin_3 = bin_3 + cluster[k]\n",
    "            bin_3_idx = bin_3_idx + idx_save[k]\n",
    "        elif result[k]==4:\n",
    "            bin_4 = bin_4 + cluster[k]\n",
    "            bin_4_idx = bin_4_idx + idx_save[k]\n",
    "        elif result[k]==5:\n",
    "            bin_5 = bin_5 + cluster[k]\n",
    "            bin_5_idx = bin_5_idx + idx_save[k]\n",
    "        elif result[k]==6:\n",
    "            bin_6 = bin_6 + cluster[k]\n",
    "            bin_6_idx = bin_6_idx + idx_save[k]\n",
    "    bin_cluster.append(bin_1)\n",
    "    bin_cluster.append(bin_2)\n",
    "    bin_cluster.append(bin_3)\n",
    "    bin_cluster.append(bin_4)\n",
    "    bin_cluster.append(bin_5)\n",
    "    bin_cluster.append(bin_6)\n",
    "    bin_index.append(bin_1_idx)\n",
    "    bin_index.append(bin_2_idx)\n",
    "    bin_index.append(bin_3_idx)\n",
    "    bin_index.append(bin_4_idx)\n",
    "    bin_index.append(bin_5_idx)\n",
    "    bin_index.append(bin_6_idx)\n",
    "    return bin_cluster, bin_index\n",
    "\n",
    "def accuracy_report(feature_m1,bin_cluster,bin_index,bin_truth):\n",
    "    final_result = [0]*len(feature_m1)\n",
    "\n",
    "    final_bin1 = bin_index[0]\n",
    "    final_bin2 = bin_index[1]\n",
    "    final_bin3 = bin_index[2]\n",
    "    final_bin4 = bin_index[3]\n",
    "    final_bin5 = bin_index[4]\n",
    "    final_bin6 = bin_index[5]\n",
    "\n",
    "    label_bin1 = [1]*len(final_bin1)\n",
    "    label_bin2 = [2]*len(final_bin2)\n",
    "    label_bin3 = [3]*len(final_bin3)\n",
    "    label_bin4 = [4]*len(final_bin4)\n",
    "    label_bin5 = [5]*len(final_bin5)\n",
    "    label_bin6 = [6]*len(final_bin6)\n",
    "    \n",
    "\n",
    "    for (i, j) in zip(final_bin1, label_bin1):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin2, label_bin2):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin3, label_bin3):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin4, label_bin4):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin5, label_bin5):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin6, label_bin6):\n",
    "        final_result[i] = j\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(len(final_result)):\n",
    "        if (final_result[i] == bin_truth[i]):\n",
    "            score = score +1\n",
    "    final_score = score/(len(final_result))\n",
    "#     print(\"k_means accuracy is: \", final_score)\n",
    "    return final_result\n",
    "\n",
    "def knn_score(y_predict, y_test):\n",
    "    score = 0\n",
    "    for i in range(len(y_predict)):\n",
    "        if (y_predict[i] == y_test[i]):\n",
    "            score = score+1\n",
    "    final_score = score/(len(y_predict))\n",
    "    print(\"KNN accuracy ------> \", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the K-fold cross validation result:\n",
      "--------------------------------------\n",
      "\n",
      "k-fold when k = 1\n",
      "SSE value of the clusters:  12.987251047611101\n",
      "KNN accuracy ------>  0.09302325581395349\n",
      "\n",
      "k-fold when k = 2\n",
      "SSE value of the clusters:  13.61768741750215\n",
      "KNN accuracy ------>  0.3333333333333333\n",
      "\n",
      "k-fold when k = 3\n",
      "SSE value of the clusters:  12.591767764440302\n",
      "KNN accuracy ------>  0.47619047619047616\n",
      "\n",
      "k-fold when k = 4\n",
      "SSE value of the clusters:  13.424871183775508\n",
      "KNN accuracy ------>  0.14285714285714285\n",
      "\n",
      "k-fold when k = 5\n",
      "SSE value of the clusters:  12.051476314798947\n",
      "KNN accuracy ------>  0.21428571428571427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(feature_m1)\n",
    "print(\"This is the K-fold cross validation result:\")\n",
    "print(\"--------------------------------------\")\n",
    "print()\n",
    "ii = 0\n",
    "for train_index, test_index in kf.split(feature_m1):\n",
    "    X_train, X_test = feature_m1[train_index], feature_m1[test_index]\n",
    "    y_train, y_test = bin_truth[train_index], bin_truth[test_index]\n",
    "    kmeans = KMeans(n_clusters= 85, random_state=0).fit(X_train)\n",
    "    print(\"k-fold when k =\",ii+1)\n",
    "    print(\"SSE value of the clusters: \",kmeans.inertia_)\n",
    "    label = kmeans.labels_\n",
    "    label = list(label)\n",
    "    index_keep = [i for i in range (len(label))]\n",
    "    bin_cluster, bin_index = try_model_kmeans(label,X_train,85,index_keep,y_train)\n",
    "#     print(\"Kmeans result:\")\n",
    "#     print(\"Bin\",\"Num\")\n",
    "#     for i in range (6):\n",
    "#         print(i+1, \" \", len(bin_cluster[i]))\n",
    "    final_label = accuracy_report(X_train,bin_cluster,bin_index,y_train)\n",
    "    knn = KNeighborsClassifier(n_neighbors=20)\n",
    "    knn.fit(X_train, final_label)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    knn_score(y_predict,y_test)\n",
    "    ii = ii+1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train the cluster by Kmeans with full dataset----\n",
      "SSE value of the clusters:  22.672399885957347\n",
      "---Save the result into a pickle file---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---Train the cluster by Kmeans with full dataset----\")\n",
    "kmeans = KMeans(n_clusters= 85 , random_state=0).fit(feature_m1)\n",
    "print(\"SSE value of the clusters: \",kmeans.inertia_)\n",
    "label = kmeans.labels_\n",
    "label = list(label)\n",
    "index_keep = [i for i in range (len(label))]\n",
    "bin_cluster, bin_index = try_model_kmeans(label,feature_m1,85,index_keep,bin_truth)\n",
    "final_label = accuracy_report(feature_m1,bin_cluster,bin_index,bin_truth)\n",
    "with open('kmeans_label.pkl','wb') as f:\n",
    "    pickle.dump(final_label, f)\n",
    "print(\"---Save the result into a pickle file---\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model_dbscan(label,feature_m1,label_class,idx_keep,bin_truth):\n",
    "    cluster = []\n",
    "    bin_cluster = []\n",
    "    bin_index = []\n",
    "    result = []\n",
    "    bin_1 = []\n",
    "    bin_2 = []\n",
    "    bin_3 = []\n",
    "    bin_4 = []\n",
    "    bin_5 = []\n",
    "    bin_6 = []\n",
    "    bin_1_idx = []\n",
    "    bin_2_idx = []\n",
    "    bin_3_idx = []\n",
    "    bin_4_idx = []\n",
    "    bin_5_idx = []\n",
    "    bin_6_idx = []\n",
    "    idx_save = []\n",
    "    for j in range (len(label_class)):\n",
    "        cluster_j = [ i for i in range(len(label)) if label[i] == label_class[j] ]\n",
    "        idx_save_j = [idx_keep[i] for i in cluster_j]\n",
    "                \n",
    "        cluster.append(cluster_j)\n",
    "        idx_save.append(idx_save_j)\n",
    "    for j in range (len(label_class)):\n",
    "        result_label = [bin_truth[i] for i in cluster[j]]\n",
    "        result.append(max(set(result_label), key=result_label.count))\n",
    "    for k in range (len(label_class)):\n",
    "        if result[k]==1:\n",
    "            bin_1 = bin_1 + cluster[k]\n",
    "            bin_1_idx = bin_1_idx + idx_save[k]\n",
    "        elif result[k]==2:\n",
    "            bin_2 = bin_2 + cluster[k]\n",
    "            bin_2_idx = bin_2_idx + idx_save[k]\n",
    "        elif result[k]==3:\n",
    "            bin_3 = bin_3 + cluster[k]\n",
    "            bin_3_idx = bin_3_idx + idx_save[k]\n",
    "        elif result[k]==4:\n",
    "            bin_4 = bin_4 + cluster[k]\n",
    "            bin_4_idx = bin_4_idx + idx_save[k]\n",
    "        elif result[k]==5:\n",
    "            bin_5 = bin_5 + cluster[k]\n",
    "            bin_5_idx = bin_5_idx + idx_save[k]\n",
    "        elif result[k]==6:\n",
    "            bin_6 = bin_6 + cluster[k]\n",
    "            bin_6_idx = bin_6_idx + idx_save[k]\n",
    "    bin_cluster.append(bin_1)\n",
    "    bin_cluster.append(bin_2)\n",
    "    bin_cluster.append(bin_3)\n",
    "    bin_cluster.append(bin_4)\n",
    "    bin_cluster.append(bin_5)\n",
    "    bin_cluster.append(bin_6)\n",
    "    bin_index.append(bin_1_idx)\n",
    "    bin_index.append(bin_2_idx)\n",
    "    bin_index.append(bin_3_idx)\n",
    "    bin_index.append(bin_4_idx)\n",
    "    bin_index.append(bin_5_idx)\n",
    "    bin_index.append(bin_6_idx)\n",
    "    return bin_cluster, bin_index\n",
    "\n",
    "def accuracy_report_dbscan(feature_m1,bin_cluster,bin_index,bin_truth):\n",
    "    temp = []\n",
    "    for i in range (6):\n",
    "        temp.append(len(bin_cluster[i]))\n",
    "    aa = temp.index(max(temp))  \n",
    "    f1 = [feature_m1[i] for i in bin_cluster[aa]]\n",
    "    bin_index_1 = bin_index[aa]\n",
    "    kmeans_1 = KMeans(n_clusters=60, random_state=0).fit(f1)\n",
    "    label_1 = list(kmeans_1.labels_)\n",
    "    bin_cluster_2nd, bin_index_2nd = try_model_kmeans(label_1,f1,60,bin_index_1,bin_truth)\n",
    "#     print(\"2-nd Kmeans result:\")\n",
    "#     print(\"Bin\",\"Num\")\n",
    "#     for i in range (6):\n",
    "#         print(i+1, \" \", len(bin_cluster_2nd[i]))\n",
    "#     print()\n",
    "    final_result = [0]*len(feature_m1)\n",
    "    final_bin1 = bin_index_2nd[0]\n",
    "    final_bin2 = bin_index[1]+bin_index_2nd[1]\n",
    "    final_bin3 = bin_index[2]+bin_index_2nd[2]\n",
    "    final_bin4 = bin_index[3]+bin_index_2nd[3]\n",
    "    final_bin5 = bin_index[4]+bin_index_2nd[4]\n",
    "    final_bin6 = bin_index[5]+bin_index_2nd[5]\n",
    "\n",
    "#     final_bin1 = bin_index[0]\n",
    "#     final_bin2 = bin_index[1]\n",
    "#     final_bin3 = bin_index[2]\n",
    "#     final_bin4 = bin_index[3]\n",
    "#     final_bin5 = bin_index[4]\n",
    "#     final_bin6 = bin_index[5]\n",
    "\n",
    "    label_bin1 = [1]*len(final_bin1)\n",
    "    label_bin2 = [2]*len(final_bin2)\n",
    "    label_bin3 = [3]*len(final_bin3)\n",
    "    label_bin4 = [4]*len(final_bin4)\n",
    "    label_bin5 = [5]*len(final_bin5)\n",
    "    label_bin6 = [6]*len(final_bin6)\n",
    "    \n",
    "\n",
    "    for (i, j) in zip(final_bin1, label_bin1):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin2, label_bin2):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin3, label_bin3):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin4, label_bin4):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin5, label_bin5):\n",
    "        final_result[i] = j\n",
    "\n",
    "    for (i, j) in zip(final_bin6, label_bin6):\n",
    "        final_result[i] = j\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(len(final_result)):\n",
    "        if (final_result[i] == bin_truth[i]):\n",
    "            score = score +1\n",
    "    final_score = score/(len(final_result))\n",
    "    print(\"SSE value of the clusters: \",kmeans_1.inertia_)\n",
    "#     print(\"reported accuracy is: \", final_score)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the K-fold cross validation result on DBSCAN method:\n",
      "--------------------------------------\n",
      "\n",
      "SSE value of the clusters:  14.76033235963526\n",
      "KNN accuracy ------>  0.046511627906976744\n",
      "\n",
      "SSE value of the clusters:  17.92506373530783\n",
      "KNN accuracy ------>  0.047619047619047616\n",
      "\n",
      "SSE value of the clusters:  15.008799889393371\n",
      "KNN accuracy ------>  0.2619047619047619\n",
      "\n",
      "SSE value of the clusters:  12.59007948180211\n",
      "KNN accuracy ------>  0.23809523809523808\n",
      "\n",
      "SSE value of the clusters:  10.760620968271573\n",
      "KNN accuracy ------>  0.30952380952380953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(feature_m1)\n",
    "print(\"This is the K-fold cross validation result on DBSCAN method:\")\n",
    "print(\"--------------------------------------\")\n",
    "print()\n",
    "\n",
    "ii = 0\n",
    "for train_index, test_index in kf.split(feature_m1):\n",
    "    X_train, X_test = feature_m1[train_index], feature_m1[test_index]\n",
    "    y_train, y_test = bin_truth[train_index], bin_truth[test_index]\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=3).fit(X_train)\n",
    "    label = dbscan.labels_\n",
    "    label_class = np.unique(label)\n",
    "    label = list(label)\n",
    "    index_keep = [i for i in range (len(label))]\n",
    "    bin_cluster, bin_index = try_model_dbscan(label,X_train,label_class,index_keep,y_train)\n",
    "#     print(\"1-st dbscan result:\")\n",
    "#     print(\"Bin\",\"Num\")\n",
    "#     for i in range (6):\n",
    "#         print(i+1, \" \", len(bin_cluster[i]))\n",
    "    final_label = accuracy_report_dbscan(X_train,bin_cluster,bin_index,y_train)\n",
    "    knn = KNeighborsClassifier(n_neighbors=20)\n",
    "    knn.fit(X_train, final_label)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    knn_score(y_predict,y_test)\n",
    "    ii = ii+1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train the cluster using DBSCAN with full dataset----\n",
      "SSE value of the clusters:  16.64912245967133\n",
      "---Save the result into a pickle file---\n"
     ]
    }
   ],
   "source": [
    "print(\"---Train the cluster using DBSCAN with full dataset----\")\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=3).fit(feature_m1)\n",
    "label = dbscan.labels_\n",
    "label_class = np.unique(label)\n",
    "# print(label)\n",
    "# print(label_class)\n",
    "label = list(label)\n",
    "index_keep = [i for i in range (len(label))]\n",
    "bin_cluster, bin_index = try_model_dbscan(label,feature_m1,label_class,index_keep,bin_truth)\n",
    "final_label = accuracy_report_dbscan(feature_m1,bin_cluster,bin_index,bin_truth)\n",
    "with open('dbscan_label.pkl','wb') as f:\n",
    "    pickle.dump(final_label, f)\n",
    "print(\"---Save the result into a pickle file---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
