{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file and save data into separate lists\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that I assume you have one mealdata for us to test\n",
    "# You didn't clarify the format of the testing data with me\n",
    "# I have to write it based on my assumption\n",
    "# You have to modify the code if it doesn't fit with the testing data\n",
    "\n",
    "# when read the data from CSV, the time stamp and associated GMC value should be reversed\n",
    "def read_raw_data():\n",
    "    x_1 =[]\n",
    "    with open(r'proj3_test.csv','rt')as f:# the path MUST be modified!!!!\n",
    "        data = csv.reader(f)\n",
    "        for row in data:\n",
    "            x_1.append(row)\n",
    "    return x_1\n",
    "\n",
    "# this func is used to remove the data which contains 'NaN' and only use the first 30 data\n",
    "def smooth_data(y):\n",
    "    idx = []\n",
    "    size_y = len(y)\n",
    "    for i in range (size_y):\n",
    "        y[i] = y[i][:30]\n",
    "        y[i] = y[i][::-1]\n",
    "        if (len(y[i])!= 30):\n",
    "            idx.append(i)\n",
    "        elif '0' in y[i]:\n",
    "            idx.append(i)      \n",
    "    for j in range (len(idx),0,-1):\n",
    "        del y[idx[j-1]]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from meal data: 51\n",
      "Number of rows from the processed meal data:  43\n"
     ]
    }
   ],
   "source": [
    "x1= read_raw_data()\n",
    "print('Number of rows from meal data:',len(x1))\n",
    "\n",
    "x1 = smooth_data(x1)\n",
    "print(\"Number of rows from the processed meal data: \",len(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the avg of changing velocity with window size 3, result in 10 features\n",
    "def avg_vel(y):\n",
    "    average = sum(y)/len(y)\n",
    "    vel_y = []\n",
    "    avg_vel = []\n",
    "    window_size = 3\n",
    "    for i in range (len(y)-1):\n",
    "        vel = y[i+1]-y[i]\n",
    "        vel_y.append(vel)\n",
    "    np.asarray(vel_y)\n",
    "\n",
    "    for i in range (int(len(y)/window_size)):\n",
    "        if i != (int((len(y)/window_size)-1)):\n",
    "            avg = np.average(vel_y[(i*3):(i*3)+3])\n",
    "        avg_vel.append(avg)\n",
    "    array_vel = np.asarray(avg_vel)\n",
    "    array_vel = normalize(array_vel[:,np.newaxis], axis=0).ravel()\n",
    "#     array_vel = (array_vel - min(array_vel))/(max(array_vel)-min(array_vel))\n",
    "    return array_vel\n",
    "\n",
    "# function for calculating the avg of meal amount with window size 3, result in 10 features\n",
    "def avg_win(y):\n",
    "    avg_win = []\n",
    "    window_size = 3\n",
    "    for i in range (int(len(y)/window_size)):\n",
    "        if i != (int((len(y)/window_size)-1)):\n",
    "            avg = np.average(y[(i*3):(i*3)+3])\n",
    "        avg_win.append(avg)\n",
    "    array_win = np.asarray(avg_win)\n",
    "    array_win = normalize(array_win[:,np.newaxis], axis=0).ravel()\n",
    "#     array_vel = (array_vel - min(array_vel))/(max(array_vel)-min(array_vel))\n",
    "    return array_win\n",
    "\n",
    "def max_increase(y):\n",
    "    change = []\n",
    "    y = list(map(int, y))\n",
    "    y_0 = y[5]\n",
    "    y_max = max(y[5:])\n",
    "    y_end = y[29]\n",
    "    max_increase = (y_max - y_0)/y_0\n",
    "    max_decrease = (y_max - y_end)/y_end\n",
    "    before_change = max(y[:5])-min(y[:5])\n",
    "    change.append(max_increase)\n",
    "    change.append(max_decrease)\n",
    "    change.append(before_change)\n",
    "    change = np.asarray(change,dtype=np.float32)\n",
    "    changed = normalize(change[:,np.newaxis], axis=0).ravel()\n",
    "#     changed = (change-min(change))/(max(change)-min(change))\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature and save it into feature metricx\n",
    "for i in range(len(x1)):\n",
    "    yy = np.asarray(x1[i],dtype=np.float32)\n",
    "    f1 = avg_vel(yy)\n",
    "    f2 = max_increase(yy)\n",
    "    f1 = np.concatenate((f1, f2), axis=None)\n",
    "#     f3 = avg_win(yy)\n",
    "#     f1 = np.concatenate((f12, f3), axis=None)\n",
    "    if i == 0:\n",
    "        feature_m1 = f1\n",
    "    else:\n",
    "        feature_m1 = np.vstack((feature_m1,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = open(\"feature_m1.pkl\",\"rb\")\n",
    "feature = pickle.load(feature)\n",
    "k_means_label = open(\"kmeans_label.pkl\",\"rb\")\n",
    "k_means_label = pickle.load(k_means_label)\n",
    "dbscan_label = open(\"dbscan_label.pkl\",\"rb\")\n",
    "dbscan_label = pickle.load(dbscan_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_kmeans = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_kmeans.fit(feature, k_means_label)\n",
    "y_predict1 = knn_kmeans.predict(feature_m1)\n",
    "y_predict1 = np.asarray(y_predict1)\n",
    "y_predict1 = y_predict1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dbscan = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_dbscan.fit(feature, dbscan_label)\n",
    "y_predict2 = knn_dbscan.predict(feature_m1)\n",
    "y_predict2 = np.asarray(y_predict2)\n",
    "y_predict2 = y_predict2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = np.column_stack([y_predict1,y_predict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ save result to result.csv ------\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('result.csv', new_array, fmt=\"%d\", delimiter=\",\")\n",
    "print(\"------ save result to result.csv ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
